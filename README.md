## Updated on 2022.03.01

## Face Reenactment

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2022-02-25**|**FSGANv2: Improved Subject Agnostic Face Swapping and Reenactment**|Yuval Nirkin et.al.|[2202.12972v1](http://arxiv.org/abs/2202.12972v1)|null|
|**2022-02-22**|**Thinking the Fusion Strategy of Multi-reference Face Reenactment**|Takuya Yashima et.al.|[2202.10758v1](http://arxiv.org/abs/2202.10758v1)|null|
|**2022-01-31**|**Finding Directions in GAN's Latent Space for Neural Face Reenactment**|Stella Bounareli et.al.|[2202.00046v1](http://arxiv.org/abs/2202.00046v1)|null|
|**2021-12-19**|**Initiative Defense against Facial Manipulation**|Qidong Huang et.al.|[2112.10098v1](http://arxiv.org/abs/2112.10098v1)|null|
|**2021-10-10**|**Fine-grained Identity Preserving Landmark Synthesis for Face Reenactment**|Haichao Zhang et.al.|[2110.04708v2](http://arxiv.org/abs/2110.04708v2)|null|
|**2021-09-10**|**Detection of GAN-synthesized street videos**|Omran Alamayreh et.al.|[2109.04991v2](http://arxiv.org/abs/2109.04991v2)|null|
|**2021-08-12**|**UniFaceGAN: A Unified Framework for Temporally Consistent Facial Video Editing**|Meng Cao et.al.|[2108.05650v1](http://arxiv.org/abs/2108.05650v1)|null|
|**2021-07-30**|**Neural Relighting and Expression Transfer On Video Portraits**|Youjia Wang et.al.|[2107.14735v4](http://arxiv.org/abs/2107.14735v4)|null|
|**2021-07-07**|**Egocentric Videoconferencing**|Mohamed Elgharib et.al.|[2107.03109v1](http://arxiv.org/abs/2107.03109v1)|null|
|**2021-04-07**|**Single Source One Shot Reenactment using Weighted motion From Paired Feature Points**|Soumya Tripathy et.al.|[2104.03117v1](http://arxiv.org/abs/2104.03117v1)|null|
|**2021-04-07**|**Everything's Talkin': Pareidolia Face Reenactment**|Linsen Song et.al.|[2104.03061v1](http://arxiv.org/abs/2104.03061v1)|**[link](https://github.com/Linsen13/EverythingTalking)**|
|**2021-04-07**|**LI-Net: Large-Pose Identity-Preserving Face Reenactment Network**|Jin Liu et.al.|[2104.02850v1](http://arxiv.org/abs/2104.02850v1)|null|
|**2021-03-18**|**KoDF: A Large-scale Korean DeepFake Detection Dataset**|Patrick Kwon et.al.|[2103.10094v2](http://arxiv.org/abs/2103.10094v2)|null|
|**2021-02-08**|**One-shot Face Reenactment Using Appearance Adaptive Normalization**|Guangming Yao et.al.|[2102.03984v3](http://arxiv.org/abs/2102.03984v3)|null|

## Talking Faces

|Publish Date|Title|Authors|PDF|Code|
|---|---|---|---|---|
|**2022-01-19**|**Semantic-Aware Implicit Neural Audio-Driven Video Portrait Generation**|Xian Liu et.al.|[2201.07786v1](http://arxiv.org/abs/2201.07786v1)|null|
|**2022-01-18**|**Leveraging Real Talking Faces via Self-Supervision for Robust Forgery Detection**|Alexandros Haliassos et.al.|[2201.07131v1](http://arxiv.org/abs/2201.07131v1)|null|
|**2022-01-16**|**Audio-Driven Talking Face Video Generation with Dynamic Convolution Kernels**|Zipeng Ye et.al.|[2201.05986v1](http://arxiv.org/abs/2201.05986v1)|null|
|**2021-12-06**|**One-shot Talking Face Generation from Single-speaker Audio-Visual Correlation Learning**|Suzhen Wang et.al.|[2112.02749v1](http://arxiv.org/abs/2112.02749v1)|null|
|**2021-11-02**|**BiosecurID: a multimodal biometric database**|Julian Fierrez et.al.|[2111.03472v1](http://arxiv.org/abs/2111.03472v1)|null|
|**2021-10-30**|**Imitating Arbitrary Talking Style for Realistic Audio-DrivenTalking Face Synthesis**|Haozhe Wu et.al.|[2111.00203v1](http://arxiv.org/abs/2111.00203v1)|**[link](https://github.com/wuhaozhe/style_avatar)**|
|**2021-10-26**|**Emotion recognition in talking-face videos using persistent entropy and neural networks**|Eduardo Paluzo-Hidalgo et.al.|[2110.13571v1](http://arxiv.org/abs/2110.13571v1)|**[link](https://github.com/cimagroup/audiovisual-emotionrecognitionusingtda)**|
|**2021-10-16**|**Intelligent Video Editing: Incorporating Modern Talking Face Generation Algorithms in a Video Editor**|Anchit Gupta et.al.|[2110.08580v1](http://arxiv.org/abs/2110.08580v1)|null|
|**2021-09-17**|**PIRenderer: Controllable Portrait Image Generation via Semantic Neural Rendering**|Yurui Ren et.al.|[2109.08379v1](http://arxiv.org/abs/2109.08379v1)|**[link](https://github.com/renyurui/pirender)**|
|**2021-08-18**|**FACIAL: Synthesizing Dynamic Talking Face with Implicit Attribute Learning**|Chenxu Zhang et.al.|[2108.07938v1](http://arxiv.org/abs/2108.07938v1)|**[link](https://github.com/zhangchenxu528/FACIAL)**|
|**2021-07-20**|**Audio2Head: Audio-driven One-shot Talking-head Generation with Natural Head Motion**|Suzhen Wang et.al.|[2107.09293v1](http://arxiv.org/abs/2107.09293v1)|null|
|**2021-07-14**|**Parallel and High-Fidelity Text-to-Lip Generation**|Jinglin Liu et.al.|[2107.06831v2](http://arxiv.org/abs/2107.06831v2)|null|
|**2021-07-10**|**Speech2Video: Cross-Modal Distillation for Speech to Video Generation**|Shijing Si et.al.|[2107.04806v1](http://arxiv.org/abs/2107.04806v1)|null|
|**2021-06-18**|**An Audio-Driven System For Real-Time Music Visualisation**|Max Graf et.al.|[2106.10134v1](http://arxiv.org/abs/2106.10134v1)|**[link](https://github.com/maxgraf96/music-vis-backend)**|
|**2021-06-08**|**LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces from Video using Pose and Lighting Normalization**|Avisek Lahiri et.al.|[2106.04185v1](http://arxiv.org/abs/2106.04185v1)|null|

